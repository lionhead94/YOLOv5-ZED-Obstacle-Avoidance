{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mGmQbAO5pQb"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wbvMlHd_QwMG",
    "outputId": "f9f016ad-3dcf-4bd2-e1c3-d5b79efc6f32"
   },
   "outputs": [],
   "source": [
    "import torch, utils, os\n",
    "# display = utils.notebook_init()  # checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload and label your dataset, and get an API KEY here: https://app.roboflow.com/?model=yolov5&ref=ultralytics\n",
      "/home/matteo/Scrivania/Test/yolov5_7.0\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Downloading Dataset Version Zip in datasets/Cans-1 to yolov5pytorch: 100% [13696694 / 13696694] bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to datasets/Cans-1 in yolov5pytorch:: 100%|‚ñà| 106\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(model_format=\"yolov5\", notebook=\"ultralytics\")\n",
    "\n",
    "%cd ~/Scrivania/Test/yolov5_7.0\n",
    "os.environ[\"DATASET_DIRECTORY\"] = \"datasets\"\n",
    "\n",
    "rf = Roboflow(api_key=\"RuqJIOzkeae0Pe0pPB2j\")\n",
    "project = rf.workspace(\"thesis-1nahg\").project(\"cans-kwabo\")\n",
    "dataset = project.version(1).download(\"yolov5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY2VXXXu74w5"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5l.pt, cfg=, data=/home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=60, batch_size=15, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 108 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 üöÄ v7.0-0-g915bbf2 Python-3.8.10 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12037MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
      " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
      " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
      " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
      " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
      " 24      [17, 20, 23]  1     43080  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
      "Model summary: 368 layers, 46149064 parameters, 46149064 gradients, 108.3 GFLOPs\n",
      "\n",
      "Transferred 607/613 items from yolov5l.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.00046875), 104 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/train/lab\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/train/labels.cache\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.2GB ram): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366/366 00:00\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/valid/label\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/valid/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 103/103 00:00\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.26 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Plotting labels to runs/train/exp17/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp17\u001b[0m\n",
      "Starting training for 60 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       0/59      8.76G    0.08504    0.03939    0.03857         12        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154     0.0749      0.384      0.103     0.0245\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       1/59      9.13G    0.06141    0.03583    0.03598         22        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.303      0.632      0.329     0.0999\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       2/59      9.13G    0.05603    0.02364    0.03472         14        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.243      0.753      0.331      0.164\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       3/59      9.13G    0.05722    0.02081    0.03255         20        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.455      0.627      0.553      0.334\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       4/59      9.13G    0.05322    0.01767    0.02759         23        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.311      0.818      0.634      0.304\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       5/59      9.13G    0.05025    0.01509    0.02278         17        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.375      0.823      0.554      0.293\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       6/59      9.13G    0.04584    0.01263    0.02033         11        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.494      0.769      0.714      0.498\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       7/59      9.13G    0.04039    0.01292    0.01779         24        640: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.631      0.941      0.895      0.641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       8/59      9.13G    0.03802    0.01152     0.0138         15        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.767      0.898      0.895      0.623\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       9/59      9.13G    0.03616    0.01109    0.00959         21        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.815      0.947      0.919      0.633\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      10/59      9.13G    0.03506    0.01165   0.007311         17        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.925      0.972      0.985      0.788\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      11/59      9.13G    0.03174    0.01171   0.006272         25        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.868      0.982      0.978      0.745\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      12/59      9.13G     0.0312    0.01058    0.00553          8        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.959      0.976      0.992      0.802\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      13/59      9.13G    0.03079    0.01021   0.004501         14        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.987      0.999      0.995      0.723\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      14/59      9.13G    0.02984    0.01007   0.003929         24        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154       0.98          1      0.995      0.773\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      15/59      9.13G    0.02747    0.01009   0.003702         17        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.992          1      0.995      0.772\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      16/59      9.13G    0.02628   0.009895   0.004222         24        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.987          1      0.995      0.834\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      17/59      9.13G     0.0251   0.009183   0.003347         13        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.995          1      0.995      0.832\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      18/59      9.13G    0.02489   0.009619   0.002976         14        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.998          1      0.995      0.836\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      19/59      9.13G    0.02384   0.008823   0.002772          8        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.998          1      0.995      0.833\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      20/59      9.13G    0.02398    0.00947   0.003126         14        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.996          1      0.995       0.82\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      21/59      9.13G    0.02299   0.009071   0.002827         19        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.997          1      0.995      0.854\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      22/59      9.13G    0.02185   0.008802   0.002586         25        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.987      0.999      0.995      0.838\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      23/59      9.13G    0.02197   0.009584   0.003142         32        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.998          1      0.995      0.882\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      24/59      9.13G    0.02192   0.008968   0.002553         12        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.998          1      0.995      0.857\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      25/59      9.13G    0.02072     0.0088   0.002229         18        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.998          1      0.995      0.841\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      26/59      9.13G    0.02062   0.008707   0.002365         19        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.998          1      0.995      0.859\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      27/59      9.13G      0.019   0.008366   0.002262         20        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.998          1      0.995      0.863\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      28/59      9.13G    0.01936   0.008028   0.002076         27        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.998          1      0.995      0.833\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      29/59      9.13G    0.01915   0.008077   0.001889         15        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.998          1      0.995      0.881\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      30/59      9.13G    0.01872   0.008046   0.002204         18        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.998          1      0.995      0.854\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      31/59      9.13G    0.01818   0.007597    0.00187         14        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.998          1      0.995      0.873\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      32/59      9.13G    0.01764   0.007812    0.00175         16        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.999          1      0.995      0.882\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      33/59      9.13G    0.01702   0.007622    0.00188         20        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.998          1      0.995      0.874\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      34/59      9.13G    0.01651   0.007977    0.00165         18        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.998          1      0.995      0.883\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      35/59      9.13G    0.01671   0.007784   0.001612         21        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.999          1      0.995      0.895\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      36/59      9.13G    0.01627   0.007941   0.001301         19        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.999          1      0.995      0.898\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      37/59      9.13G    0.01604   0.007631   0.001365         15        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.999          1      0.995      0.898\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      38/59      9.13G    0.01543   0.007639   0.001679         12        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.998          1      0.995       0.89\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      39/59      9.13G    0.01494   0.007591    0.00159         16        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.999          1      0.995      0.891\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      40/59      9.13G    0.01483   0.007493   0.001576         14        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.997          1      0.995      0.887\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      41/59      9.13G    0.01397   0.007021   0.001252         16        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.998          1      0.995      0.907\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      42/59      9.13G    0.01393    0.00716   0.001167         21        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.999          1      0.995      0.907\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      43/59      9.13G    0.01343   0.006862   0.001096         13        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.999          1      0.995      0.903\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      44/59      9.13G    0.01238   0.006779   0.001393         14        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.998          1      0.995      0.902\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      45/59      9.13G    0.01304   0.006542   0.001266         13        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.998          1      0.995      0.906\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      46/59      9.13G     0.0123   0.006601   0.001132         19        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.998          1      0.995      0.907\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      47/59      9.13G    0.01198    0.00653  0.0009724         25        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.999          1      0.995      0.912\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      48/59      9.13G    0.01189   0.006151   0.001013         16        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.997          1      0.995      0.919\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      49/59      9.13G    0.01188   0.007011   0.001694         25        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.998          1      0.995      0.914\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      50/59      9.13G    0.01133   0.006689    0.00131         17        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.998          1      0.995      0.916\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      51/59      9.13G    0.01092   0.006686   0.001211         16        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.997          1      0.995      0.917\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      52/59      9.13G    0.01018   0.006053  0.0009803         27        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.998          1      0.995      0.923\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      53/59      9.13G     0.0101   0.006169  0.0007877         18        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.998          1      0.995      0.925\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      54/59      9.13G    0.01008   0.005304   0.000718         14        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.999          1      0.995      0.919\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      55/59      9.13G   0.009529   0.005795  0.0008539         19        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.999          1      0.995      0.922\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      56/59      9.13G   0.009533   0.005516  0.0007184         15        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.998          1      0.995      0.924\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      57/59      9.13G   0.009031   0.006116  0.0009535         21        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.998          1      0.995      0.925\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      58/59      9.13G   0.008925    0.00599  0.0007803         16        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.998          1      0.995      0.924\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      59/59      9.13G   0.008368   0.005546  0.0006118         18        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.997          1      0.995      0.922\n",
      "\n",
      "60 epochs completed in 0.206 hours.\n",
      "Optimizer stripped from runs/train/exp17/weights/last.pt, 92.8MB\n",
      "Optimizer stripped from runs/train/exp17/weights/best.pt, 92.8MB\n",
      "\n",
      "Validating runs/train/exp17/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 267 layers, 46119048 parameters, 0 gradients, 107.7 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        103        154      0.998          1      0.995      0.925\n",
      "              OranSoda        103         48      0.998          1      0.995      0.931\n",
      "                 Pepsi        103         54      0.999          1      0.995      0.938\n",
      "                Sprite        103         52      0.998          1      0.995      0.907\n",
      "Results saved to \u001b[1mruns/train/exp17\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py --img 640 --batch 15 --epochs 60 --data {dataset.location}/data.yaml --weights yolov5l.pt --cache --device 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp17/weights/best.pt'], source=/home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.1, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 üöÄ v7.0-0-g915bbf2 Python-3.8.10 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12037MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 267 layers, 46119048 parameters, 0 gradients, 107.7 GFLOPs\n",
      "image 1/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-0_jpg.rf.4db5bfb285ad386f03f2b70f2060c7bb.jpg: 384x640 1 OranSoda, 1 Pepsi, 1 Sprite, 12.6ms\n",
      "image 2/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-102_jpg.rf.9b2541ce72a985188f966f7cc2e36e89.jpg: 384x640 2 OranSodas, 1 Pepsi, 1 Sprite, 9.4ms\n",
      "image 3/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-106_jpg.rf.147bc3a5ffc69564709e1826eb4ad0a7.jpg: 384x640 1 Pepsi, 9.7ms\n",
      "image 4/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-108_jpg.rf.20e41b2c98b4580ee80bbd6c1a6b82d2.jpg: 384x640 1 OranSoda, 10.5ms\n",
      "image 5/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-109_jpg.rf.83869ad013f01c7980994af610614fbb.jpg: 384x640 1 OranSoda, 10.4ms\n",
      "image 6/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-10_jpg.rf.9cd45e5155948857cdaf0ce4e64f1dbb.jpg: 384x640 1 OranSoda, 1 Pepsi, 1 Sprite, 10.2ms\n",
      "image 7/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-119_jpg.rf.a90dfdd8c6d19e4c8cd4b1bb8dafb353.jpg: 384x640 1 Pepsi, 10.1ms\n",
      "image 8/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-121_jpg.rf.68e50a45bba30f33da85a492bf6860fb.jpg: 384x640 1 Sprite, 11.2ms\n",
      "image 9/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-122_jpg.rf.63ff7cd68461aa2ea812bfcfce2aa8fd.jpg: 384x640 1 Sprite, 10.1ms\n",
      "image 10/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-124_jpg.rf.56bd633252653458cde648293b573778.jpg: 384x640 1 Pepsi, 11.2ms\n",
      "image 11/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-125_jpg.rf.0c0281d228c9caab3a52483b3165efaf.jpg: 384x640 (no detections), 10.2ms\n",
      "image 12/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-12_jpg.rf.ede25828bc2a64200845ed6b0c44034e.jpg: 384x640 1 Sprite, 11.0ms\n",
      "image 13/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-130_jpg.rf.2344a5f3618040d683af2de519eaecf8.jpg: 384x640 1 Sprite, 11.4ms\n",
      "image 14/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-134_jpg.rf.45de0e09eebcb8e1d46c3e527999aed2.jpg: 384x640 2 Pepsis, 1 Sprite, 10.2ms\n",
      "image 15/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-13_jpg.rf.b5134bd2c458d8016bee8de1d0ab17a2.jpg: 384x640 1 OranSoda, 11.2ms\n",
      "image 16/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-13_jpg.rf.f58f367ab12c6755633a0f7abef0b174.jpg: 384x640 1 Sprite, 10.6ms\n",
      "image 17/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-18_jpg.rf.083d72394123dbdbed3978aa31b0276a.jpg: 384x640 1 OranSoda, 1 Pepsi, 1 Sprite, 8.8ms\n",
      "image 18/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-19_jpg.rf.17461103a3533fa690357371629c094b.jpg: 384x640 1 Pepsi, 9.1ms\n",
      "image 19/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-1_jpg.rf.6ff9da4d3f78226aef403f80630d3968.jpg: 384x640 1 OranSoda, 9.6ms\n",
      "image 20/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-23_jpg.rf.2c5cd8af74f5ff99b136b5255f57daca.jpg: 384x640 1 OranSoda, 9.2ms\n",
      "image 21/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-24_jpg.rf.72cf23e24588285950c22617432e5b2a.jpg: 384x640 1 Sprite, 11.7ms\n",
      "image 22/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-26_jpg.rf.ab41809f876a85d2042df6de484a6386.jpg: 384x640 1 OranSoda, 10.2ms\n",
      "image 23/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-27_jpg.rf.de20e472884a93b80f5eaf415f124a09.jpg: 384x640 1 Pepsi, 8.6ms\n",
      "image 24/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-32_jpg.rf.7f1aad6b385f6c2b9e4aa7f3beba5891.jpg: 384x640 1 OranSoda, 8.7ms\n",
      "image 25/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-37_jpg.rf.a39241755fa0cdb56eefd90e66ee4a7b.jpg: 384x640 1 Pepsi, 9.5ms\n",
      "image 26/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-39_jpg.rf.6164a465e7c9b9efc0c19b1754358fcd.jpg: 384x640 1 OranSoda, 9.5ms\n",
      "image 27/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-3_jpg.rf.27b2e0eaf48e924b1658b1bc37b047de.jpg: 384x640 1 OranSoda, 1 Pepsi, 1 Sprite, 10.4ms\n",
      "image 28/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-3_jpg.rf.73999d8ce22fcf97bd3021b00e672c44.jpg: 384x640 1 Sprite, 10.9ms\n",
      "image 29/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-47_jpg.rf.ddcedc01df182934f95e91fa0ecbbccd.jpg: 384x640 1 OranSoda, 1 Pepsi, 1 Sprite, 10.1ms\n",
      "image 30/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-4_jpg.rf.b5aaa9473587cbbaeb710dad926d9c4a.jpg: 384x640 1 Pepsi, 11.8ms\n",
      "image 31/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-51_jpg.rf.192154d53db5295c4dbd96d8ab048010.jpg: 384x640 1 OranSoda, 1 Pepsi, 1 Sprite, 10.2ms\n",
      "image 32/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-52_jpg.rf.f40618b2bbafa0c42d2b7aec33336ac4.jpg: 384x640 1 OranSoda, 11.1ms\n",
      "image 33/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-53_jpg.rf.f60cda4c8b8550292e2f399e7c8c661c.jpg: 384x640 1 Sprite, 10.9ms\n",
      "image 34/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-54_jpg.rf.504d10e9d9a105fe2d2b4e674cd9c81d.jpg: 384x640 1 OranSoda, 1 Pepsi, 1 Sprite, 9.1ms\n",
      "image 35/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-55_jpg.rf.00ffbe638e78c902ad10813e703b9b03.jpg: 384x640 1 Sprite, 8.7ms\n",
      "image 36/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-55_jpg.rf.e500417c685acbdb80455fd160dd66a8.jpg: 384x640 1 Pepsi, 8.7ms\n",
      "image 37/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-57_jpg.rf.031892063dc062bd61b930dd3e1ba880.jpg: 384x640 1 OranSoda, 1 Pepsi, 1 Sprite, 9.0ms\n",
      "image 38/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-58_jpg.rf.ff510eb68b6cc505e775063ecc92fb27.jpg: 384x640 1 Sprite, 10.5ms\n",
      "image 39/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-59_jpg.rf.4d9d85b7f226eaff4caac5f5510894b4.jpg: 384x640 1 OranSoda, 9.4ms\n",
      "image 40/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-59_jpg.rf.a3f448a46f9613ffc18d833c7ec469da.jpg: 384x640 1 Pepsi, 9.9ms\n",
      "image 41/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-60_jpg.rf.4b9a9fe7a4d563a00d104ec619d5116b.jpg: 384x640 1 Sprite, 12.0ms\n",
      "image 42/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-65_jpg.rf.9ab417ca0aea4c35985e5d20107b9bab.jpg: 384x640 1 OranSoda, 1 Pepsi, 1 Sprite, 9.8ms\n",
      "image 43/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-66_jpg.rf.0750d3119fd6447d542c47ad04bce050.jpg: 384x640 1 Sprite, 11.3ms\n",
      "image 44/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-71_jpg.rf.f11472fa40d77fbaaa5dbbce21c5cf8f.jpg: 384x640 1 OranSoda, 1 Pepsi, 1 Sprite, 11.6ms\n",
      "image 45/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-72_jpg.rf.c4afba36ad27732f4d874c747db3e2b1.jpg: 384x640 1 OranSoda, 1 Pepsi, 1 Sprite, 8.3ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 46/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-72_jpg.rf.eaf7191abe2e450876c49ea3b8446230.jpg: 384x640 1 OranSoda, 9.7ms\n",
      "image 47/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-76_jpg.rf.b99fb3041208a2a034e8c6842c647c0a.jpg: 384x640 1 OranSoda, 9.2ms\n",
      "image 48/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-80_jpg.rf.ced38c37331702a0763cc4e4a403edde.jpg: 384x640 1 Pepsi, 9.3ms\n",
      "image 49/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-81_jpg.rf.5a07263d8ee7feed96d525bab961e248.jpg: 384x640 1 Pepsi, 9.2ms\n",
      "image 50/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-81_jpg.rf.7f65b4e442c68787b697748f0ec642d5.jpg: 384x640 1 OranSoda, 11.8ms\n",
      "image 51/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-81_jpg.rf.84b4688f9063fe79f194f12bc8f36587.jpg: 384x640 1 Sprite, 8.8ms\n",
      "image 52/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-82_jpg.rf.122eb35a9a262369b9a6e7aefec85408.jpg: 384x640 1 OranSoda, 1 Pepsi, 1 Sprite, 8.6ms\n",
      "image 53/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-8_jpg.rf.819410ca0cef0898fd05de56d6548e51.jpg: 384x640 1 Pepsi, 8.7ms\n",
      "image 54/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-90_jpg.rf.2caf069e2ce0e5f2d92eda4ca01ce498.jpg: 384x640 1 Pepsi, 8.2ms\n",
      "image 55/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-92_jpg.rf.4e6034b9f6e3c4aeb539c2dcc01ac803.jpg: 384x640 1 OranSoda, 11.2ms\n",
      "image 56/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-95_jpg.rf.4742853f5c024865ae8c970b5e214f29.jpg: 384x640 1 Sprite, 11.1ms\n",
      "image 57/57 /home/matteo/Scrivania/Test/yolov5_7.0/datasets/Cans-1/test/images/youtube-99_jpg.rf.af1503918389768a96f73627fa646a8d.jpg: 384x640 1 OranSoda, 1 Pepsi, 1 Sprite, 9.7ms\n",
      "Speed: 0.2ms pre-process, 10.1ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/exp11\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 detect.py --weights runs/train/exp17/weights/best.pt --img 640 --conf 0.1 --source {dataset.location}/test/images --device 0"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "YOLOv5 Tutorial",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "16b0c8aa6e0f427e8a54d3791abb7504": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f7df330663048998adcf8a45bc8f69b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e896e6096dd244c59d7955e2035cd729",
       "IPY_MODEL_a6ff238c29984b24bf6d0bd175c19430",
       "IPY_MODEL_3c085ba3f3fd4c3c8a6bb41b41ce1479"
      ],
      "layout": "IPY_MODEL_16b0c8aa6e0f427e8a54d3791abb7504"
     }
    },
    "3c085ba3f3fd4c3c8a6bb41b41ce1479": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df554fb955c7454696beac5a82889386",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_74e9112a87a242f4831b7d68c7da6333",
      "value": " 780M/780M [00:05&lt;00:00, 126MB/s]"
     }
    },
    "6a27e43b0e434edd82ee63f0a91036ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "74e9112a87a242f4831b7d68c7da6333": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a6ff238c29984b24bf6d0bd175c19430": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cce0e6c0c4ec442cb47e65c674e02e92",
      "max": 818322941,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c5b9f38e2f0d4f9aa97fe87265263743",
      "value": 818322941
     }
    },
    "c5b9f38e2f0d4f9aa97fe87265263743": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c7b2dd0f78384cad8e400b282996cdf5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cce0e6c0c4ec442cb47e65c674e02e92": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df554fb955c7454696beac5a82889386": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e896e6096dd244c59d7955e2035cd729": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c7b2dd0f78384cad8e400b282996cdf5",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_6a27e43b0e434edd82ee63f0a91036ca",
      "value": "100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
